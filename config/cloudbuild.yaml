steps:
  - id: "fetch mvn settings.xml and update"
    name: "gcr.io/cloud-builders/gsutil"
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        copy_cmd='gsutil cp '"$${LOCATION}"'/config/settings.xml .'
        $copy_cmd
        sed -i -e 's/CLAMP_REG_PASSWORD/'"$${CLAMP_REG_PASSWORD}"'/g' settings.xml
    secretEnv: ['LOCATION', 'CLAMP_REG_PASSWORD']
  - id: "build and deploy to dataflow"
    name: "gcr.io/cloud-builders/mvn:3.5.0-jdk-8"
    entrypoint: 'bash'
    env:
      - 'PRIVATE_CLAMP_REPO_URL=${_PRIVATE_CLAMP_REPO_URL}'
    args:
      - '-c'
      - |
        echo "Build identifier = ${BUILD_ID}_${SHORT_SHA}"
        mvn compile exec:java \
          --settings settings.xml \
          -Dexec.mainClass="org.allofus.curation.pipeline.CurationNLPMain" \
          -Dexec.args="--project=${PROJECT_ID} \
            --gcpTempLocation=$${LOCATION}/gcp_tmp \
            --stagingLocation=$${LOCATION}/staging \
            --tempLocation=$${LOCATION}/tmp \
            --runner=DataflowRunner \
            --region=${LOCATION} \
            --input=$${INPUT} \
            --output=$${OUTPUT} \
            --pipeline=$${PIPELINE} \
            --resourcesDir=$${LOCATION}/resources \
            --inputType=$${DATATYPE} \
            --outputType=$${DATATYPE} \
            --subnetwork=$${SUBNET} \
            --workerMachineType=$${WORKER_MACHINE_TYPE} \
            --diskSizeGb=$${DISK_SIZE_GB} \
            --maxNumWorkers=$${MAX_NUM_WORKERS} \
            --numberOfWorkerHarnessThreads=$${NUM_WORKER_THREADS} \
            --maxClampThreads=$${MAX_CLAMP_THREADS} \
            --maxOutputPartitionSeconds=$${MAX_OUTPUT_PARTITION_SECONDS} \
            --maxOutputBatchSize=$${MAX_OUTPUT_BATCH_SIZE} \
            --buildId=${BUILD_ID}_${SHORT_SHA} \
            --usePublicIps=false \
            --experiments=$${EXPERIMENTS} \
            $${STREAMING}" \
          -Pdataflow-runner -P dataflow
    secretEnv: ['LOCATION', 'SUBNET']
availableSecrets:
  secretManager:
    - versionName: projects/${PROJECT_ID}/secrets/dataflow-location/versions/latest
      env: 'LOCATION'
    - versionName: projects/${PROJECT_ID}/secrets/dataflow-subnet/versions/latest
      env: 'SUBNET'
    - versionName: projects/${PROJECT_ID}/secrets/artifact-reg-clamp-password/versions/latest
      env: 'CLAMP_REG_PASSWORD'
    - versionName: projects/${PROJECT_ID}/secrets/dataflow-input/versions/latest
      env: 'INPUT'
    - versionName: projects/${PROJECT_ID}/secrets/dataflow-output/versions/latest
      env: 'OUTPUT'
    - versionName: projects/${PROJECT_ID}/secrets/dataflow-pipeline/versions/latest
      env: 'PIPELINE'
    - versionName: projects/${PROJECT_ID}/secrets/dataflow-datatype/versions/latest
      env: 'DATATYPE'
    - versionName: projects/${PROJECT_ID}/secrets/dataflow-max-workers/versions/latest
      env: 'MAX_NUM_WORKERS'
    - versionName: projects/${PROJECT_ID}/secrets/dataflow-num-worker-threads/versions/latest
      env: 'NUM_WORKER_THREADS'
    - versionName: projects/${PROJECT_ID}/secrets/max-clamp-threads/versions/latest
      env: 'MAX_CLAMP_THREADS'
    - versionName: projects/${PROJECT_ID}/secrets/dataflow-machine-type/versions/latest
      env: 'WORKER_MACHINE_TYPE'
    - versionName: projects/${PROJECT_ID}/secrets/dataflow-disk-size/versions/latest
      env: 'DISK_SIZE_GB'
    - versionName: projects/${PROJECT_ID}/secrets/max-output-batch-size/versions/latest
      env: 'MAX_OUTPUT_BATCH_SIZE'
    - versionName: projects/${PROJECT_ID}/secrets/max-output-partition-seconds/versions/latest
      env: 'MAX_OUTPUT_PARTITION_SECONDS'
    - versionName: projects/${PROJECT_ID}/secrets/dataflow-streaming/versions/latest
      env: 'STREAMING'
    - versionName: projects/${PROJECT_ID}/secrets/dataflow-experiments/versions/latest
      env: 'EXPERIMENTS'
